{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1SdiYblJx2ao",
    "tags": []
   },
   "source": [
    "# Create covisitation matrices to be used in candidate generation #\n",
    "We create three types of covisitation matrix:\n",
    "1. What else did people who clicked/carted/ordered the focal product also click/cart/order weighted to those occuring more recently in the data\n",
    "2. What else did people who clicked/carted/ordered the focal product also click/cart/order weighted to items being carted and ordered. \n",
    "3. What else did people who carted/ordered the product also cart/order. \n",
    "\n",
    "The joining operations are memory intensive so we split the dataframe into chunks and work through piecewise to avoid running out of ram.\n",
    "\n",
    "This process is inspired by this kaggle post: https://www.kaggle.com/code/cdeotte/candidate-rerank-model-lb-0-575"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd kaggle-otto-recommender-2022/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf train_candidate_features/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import local, data_path, path_to_module\n",
    "\n",
    "sample_prop = None\n",
    "validation = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/kaggle-otto-recommender-2022/data'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/kaggle-otto-recommender-2022'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "rgw3DUBDx7hN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jupyter/kaggle-otto-recommender-2022/data\n"
     ]
    }
   ],
   "source": [
    "if local:\n",
    "  # from google.colab import drive\n",
    "  # drive.mount('/content/drive')\n",
    "  # %cd /content/drive/MyDrive/'Kaggle Otto Reccommender'/data\n",
    "  # path_to_module = '/content/drive/MyDrive/Kaggle Otto Reccommender/'\n",
    "    pass\n",
    "else:\n",
    "    # !mkdir /my_mnt_dir\n",
    "    # !google-drive-ocamlfuse /my_mnt_dir\n",
    "    %cd {data_path}\n",
    "    # path_to_module = '/home/jupyter/kaggle-otto-recommender-2022'\n",
    "\n",
    "import sys    \n",
    "sys.path.append(path_to_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path_to_module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "bbpCdPcQOMqe"
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gc\n",
    "from tqdm import tqdm\n",
    "from otto_utils import get_train, get_test, convert_columns, make_directory\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ExzF1gWlEUUK"
   },
   "outputs": [],
   "source": [
    "# !pip install fastparquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "wJuOKZmKTHVb"
   },
   "outputs": [],
   "source": [
    "\n",
    "path_to_candidate_features = './train_candidate_features' if validation else './test_candidate_features'\n",
    "make_directory(path_to_candidate_features)\n",
    "make_directory(f'{path_to_candidate_features}/covisitation_parquet')\n",
    "make_directory(f'{path_to_candidate_features}/cart_order_parquet')\n",
    "make_directory(f'{path_to_candidate_features}/also_buy_parquet')\n",
    "n=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./train_candidate_features'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_to_candidate_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/jupyter/kaggle-otto-recommender-2022/data'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Read data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "DbyydmmcNB80",
    "tags": []
   },
   "outputs": [],
   "source": [
    "reduced_df = pd.concat([get_train(validation=validation, sample_prop=sample_prop), get_test(validation=validation, sample_prop=sample_prop)])\n",
    "reduced_df['ts'] = reduced_df['ts'] / 1000\n",
    "reduced_df['ts'] = reduced_df['ts'].astype('int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "FjqDOBh6ttXX"
   },
   "outputs": [],
   "source": [
    "reduced_df = convert_columns(reduced_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "BE56LzDP714K"
   },
   "outputs": [],
   "source": [
    "sessions = reduced_df['session'].unique()\n",
    "sessions.sort()\n",
    "aids = reduced_df['aid'].unique()\n",
    "aids.sort()\n",
    "\n",
    "session_lists = [np_array.tolist() for np_array in np.array_split(np.array(sessions), int(reduced_df.shape[0]*200 / 163955180)) ]\n",
    "aid_lists = [np_array.tolist() for np_array in np.array_split(np.array(aids), int(reduced_df.shape[0]*100 / 163955180)) ]\n",
    "max_ts = 1662328791\n",
    "min_ts = 1659304800\n",
    "diff_ts = max_ts - min_ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "2hGT0nQQv3D_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100% 209/209 [02:39<00:00,  1.31it/s]\n"
     ]
    }
   ],
   "source": [
    "sorted_chunks = []\n",
    "for session_list in tqdm(session_lists):\n",
    "  chunk = reduced_df[(reduced_df['session'] >= min(session_list)) & (reduced_df['session'] <= max(session_list))]\n",
    "  chunk = chunk.sort_values(['session','ts'],ascending=[True,False])\n",
    "  chunk = chunk.reset_index(drop=True)\n",
    "  chunk['n'] = chunk.groupby('session').cumcount()\n",
    "  chunk = chunk.loc[chunk.n<30].drop('n',axis=1)\n",
    "  sorted_chunks.append(chunk)\n",
    "reduced_df = pd.concat(sorted_chunks)\n",
    "del sorted_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115162296, 4)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Matrix 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Whtc1gRL7Vyh"
   },
   "source": [
    "Build the clicks/cart/order to clicks/cart/order covisitation matrix weighted towards things happening more recently. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test  train_candidate_features\tvalidation\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ioT9gteQTZBv"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/104 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "for i, aid_list in enumerate(tqdm(aid_lists)):\n",
    "  tmp_list = []\n",
    "\n",
    "  for session_list in session_lists:\n",
    "    df = reduced_df[(reduced_df['session'] >= min(session_list)) & (reduced_df['session'] <= max(session_list))]\n",
    "    tmp = (\n",
    "        df.loc[(df['aid'] >= min(aid_list)) & (df['aid'] <= max(aid_list))]\n",
    "        .merge(df,\n",
    "              how = 'inner',\n",
    "              on = 'session')\n",
    "    )\n",
    "    tmp = (\n",
    "        tmp\n",
    "        .loc[ ((tmp.ts_x - tmp.ts_y).abs() < 24 * 60 * 60) & (tmp.aid_x != tmp.aid_y) ]\n",
    "        .drop_duplicates(['session', 'aid_x', 'aid_y'])\n",
    "    )\n",
    "    tmp['wgt'] = 1 + 3 * (tmp.ts_x - min_ts) / diff_ts\n",
    "    tmp = (\n",
    "        tmp.groupby(['aid_x', 'aid_y'], as_index=False)\n",
    "        .agg({'wgt' : 'sum'})\n",
    "        .rename(columns={'wgt' : 'pairings'})\n",
    "    )\n",
    "    tmp['pairings'] = tmp['pairings'].astype('float32')\n",
    "    tmp_list.append(tmp)\n",
    "  out = pd.concat(tmp_list)\n",
    "  out = (\n",
    "      pd.concat(tmp_list)\n",
    "      .groupby(['aid_x', 'aid_y'], as_index=False)\n",
    "      .agg({'pairings' : 'sum'})\n",
    "      .sort_values(by=['aid_x', 'pairings'], ascending=[True, False])\n",
    "  )\n",
    "\n",
    "  out['n'] = out.groupby(['aid_x']).cumcount() + 1\n",
    "  out = out.loc[out['n'] <= n]\n",
    "  for column in ['aid_x', 'aid_y']:\n",
    "    out[column] = out[column].astype('int32')\n",
    "  out.to_parquet(f'{path_to_candidate_features}/covisitation_parquet/wgt_covisitation_{i}_top{n}.parquet', index=False)\n",
    "  del tmp_list, out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kWfk0ELK7emM"
   },
   "source": [
    "Build the clicks/cart/order to clicks/cart/order weighted towards carts/orders matrix weighted by the type of interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covisitation Matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z6vjqfnFSvYw"
   },
   "outputs": [],
   "source": [
    "type_weight_map = {\n",
    "    'clicks' : 1,\n",
    "    'carts' : 6,\n",
    "    'orders' : 3\n",
    "}\n",
    "\n",
    "for i, aid_list in enumerate(tqdm(aid_lists)):\n",
    "  tmp_list = []\n",
    "\n",
    "  for session_list in session_lists:\n",
    "    df = reduced_df[(reduced_df['session'] >= min(session_list)) & (reduced_df['session'] <= max(session_list))]\n",
    "    tmp = (\n",
    "        df.loc[(df['aid'] >= min(aid_list)) & (df['aid'] <= max(aid_list))]\n",
    "        .merge(df,\n",
    "              how = 'inner',\n",
    "              on = 'session')\n",
    "    )\n",
    "    tmp = (\n",
    "        tmp\n",
    "        .loc[ ((tmp.ts_x - tmp.ts_y).abs() < 24 * 60 * 60) & (tmp.aid_x != tmp.aid_y) ]\n",
    "    )\n",
    "    tmp['wgt'] = tmp['type_y'].map(type_weight_map)\n",
    "    tmp = (\n",
    "        tmp.groupby(['aid_x', 'aid_y'], as_index=False)\n",
    "        .agg({'wgt' : 'sum'})\n",
    "        .rename(columns={'wgt' : 'pairings'})\n",
    "    )\n",
    "    tmp['pairings'] = tmp['pairings'].astype('int32')\n",
    "    tmp_list.append(tmp)\n",
    "  out = pd.concat(tmp_list)\n",
    "  out = (\n",
    "      pd.concat(tmp_list)\n",
    "      .groupby(['aid_x', 'aid_y'], as_index=False)\n",
    "      .agg({'pairings' : 'sum'})\n",
    "      .sort_values(by=['aid_x', 'pairings'], ascending=[True, False])\n",
    "  )\n",
    "\n",
    "  out['n'] = out.groupby(['aid_x']).cumcount() + 1\n",
    "  out = out.loc[out['n'] <= 15]\n",
    "\n",
    "  for column in ['aid_x', 'aid_y']:\n",
    "    out[column] = out[column].astype('int32')\n",
    "  out.to_parquet(f'{path_to_candidate_features}/cart_order_parquet/cart_order_top15_{i}.parquet', index=False)\n",
    "  \n",
    "  del tmp_list, out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9BI2NtlG8Yuu"
   },
   "source": [
    "Build the covisitation of what people carted/ordered alongside carts and orders. E.g those that bought x also bought... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Also Buy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K1-ENh39FbfY"
   },
   "outputs": [],
   "source": [
    "session_lists = [np_array.tolist() for np_array in np.array_split(np.array(sessions), int(reduced_df.shape[0]*3 / 163955180)) ]\n",
    "aid_lists = [np_array.tolist() for np_array in np.array_split(np.array(aids), int(reduced_df.shape[0]*10 / 163955180)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "it_GRoK8cjhC"
   },
   "outputs": [],
   "source": [
    "for i, aid_list in enumerate(tqdm(aid_lists)):\n",
    "  tmp_list = []\n",
    "\n",
    "  for session_list in session_lists:\n",
    "    df = reduced_df[(reduced_df['session'] >= min(session_list)) & (reduced_df['session'] <= max(session_list))]\n",
    "    df = df.loc[df['type'].isin(['carts', 'orders'])]\n",
    "    tmp = (\n",
    "        df.loc[(df['aid'] >= min(aid_list)) & (df['aid'] <= max(aid_list))]\n",
    "        .merge(df,\n",
    "              how = 'inner',\n",
    "              on = 'session')\n",
    "    )\n",
    "    tmp = (\n",
    "        tmp\n",
    "        .loc[ ((tmp.ts_x - tmp.ts_y).abs() < 14 * 24 * 60 * 60) & (tmp.aid_x != tmp.aid_y) ]\n",
    "    )\n",
    "    tmp['wgt'] = 1\n",
    "    tmp = (\n",
    "        tmp.groupby(['aid_x', 'aid_y'], as_index=False)\n",
    "        .agg({'wgt' : 'sum'})\n",
    "        .rename(columns={'wgt' : 'pairings'})\n",
    "    )\n",
    "    tmp['pairings'] = tmp['pairings'].astype('int32')\n",
    "    tmp_list.append(tmp)\n",
    "  out = pd.concat(tmp_list)\n",
    "  out = (\n",
    "      pd.concat(tmp_list)\n",
    "      .groupby(['aid_x', 'aid_y'], as_index=False)\n",
    "      .agg({'pairings' : 'sum'})\n",
    "      .sort_values(by=['aid_x', 'pairings'], ascending=[True, False])\n",
    "  )\n",
    "\n",
    "  out['n'] = out.groupby(['aid_x']).cumcount() + 1\n",
    "  out = out.loc[out['n'] <= 15]\n",
    "\n",
    "  for column in ['aid_x', 'aid_y']:\n",
    "    out[column] = out[column].astype('int32')\n",
    "  out.to_parquet(f'{path_to_candidate_features}/also_buy_parquet/also_buy_top15_{i}.parquet', index=False)\n",
    "  \n",
    "  del tmp_list, out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_candidate_features"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNSoRGgKYL5bDzuwHVceDPy",
   "machine_shape": "hm",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
